{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c9fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561db666",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83941261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAIN_DATASET = pd.read_csv(\"train.csv\")\n",
    "VALIDATION_DATASET = pd.read_csv(\"validation.csv\")\n",
    "TEST_DATASET = pd.read_csv(\"test.csv\")\n",
    "NUMBER_OF_JOBS = 1\n",
    "\n",
    "# Benchmarking multiple models\n",
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state = SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state = SEED),\n",
    "    \"Support Vector Machine\": SVC(random_state = SEED),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106dc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_data, vectorizer, model):\n",
    "    \"\"\"Fits a model on train data\"\"\"\n",
    "    X_train = vectorizer.fit_transform(train_data[\"text\"])\n",
    "    y_train = train_data[\"spam\"]\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, vectorizer\n",
    "\n",
    "def score_model(model, vectorizer, data):\n",
    "    \"\"\"Scores a model on given data\"\"\"\n",
    "    X = vectorizer.transform(data[\"text\"])\n",
    "    y_true = data[\"spam\"]\n",
    "    y_pred = model.predict(X)\n",
    "    return accuracy_score(y_true, y_pred), classification_report(y_true, y_pred), confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def cross_validate_model(model, vectorizer, data):\n",
    "    \"\"\"Validates the model using cross-validation\"\"\"\n",
    "    X = vectorizer.transform(data[\"text\"])\n",
    "    y = data[\"spam\"]\n",
    "    return cross_val_score(model, X, y, cv = 5, scoring = \"recall\").mean()\n",
    "\n",
    "def score_and_evaluate_model(model, vectorizer, data, data_type):\n",
    "    \"\"\"Scores and evaluates model\"\"\"\n",
    "    accuracy, report, confusion_mat = score_model(model, vectorizer, data)\n",
    "    print(f\"{data_type} Accuracy: {round(100 * accuracy, 2)} %\")\n",
    "    print(f\"{data_type} Classification Report:\\n{report}\")\n",
    "    print(f\"{data_type} Confusion Matrix:\\n{confusion_mat}\")\n",
    "    return accuracy\n",
    "\n",
    "def fine_tune_model(model, vectorizer, train_data, validation_data):\n",
    "    \"\"\"Fine-tunes the model based on train and validation\"\"\"\n",
    "    combined_data = pd.concat([train_data, validation_data], axis = 0)\n",
    "    param_grid = {}\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        param_grid = {\"penalty\": [\"l1\", \"l2\"], \"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"solver\": [\"liblinear\", \"saga\"], \"max_iter\": [100, 200, 300]}\n",
    "    elif isinstance(model, RandomForestClassifier):\n",
    "        param_grid = {\"n_estimators\": [100, 200], \"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5], \"min_samples_leaf\": [1, 2], \"max_features\": [\"auto\", \"sqrt\"], \"bootstrap\": [True, False]}\n",
    "    elif isinstance(model, SVC):\n",
    "        param_grid = {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \"degree\": [2, 3, 4], \"gamma\": [\"scale\", \"auto\"], \"shrinking\": [True, False]}\n",
    "    grid_search = GridSearchCV(model, param_grid, cv = 5, scoring = \"recall\", n_jobs = -1)\n",
    "    X_combined = vectorizer.transform(combined_data[\"text\"])\n",
    "    y_combined = combined_data[\"spam\"]\n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def train_and_benchmark_model(model, model_name, train_data, validation_data, test_data):\n",
    "    \"\"\"Trains and benchmarks model\"\"\"\n",
    "    print(f\"\\nTraining and Evaluating {model_name}:\\n\")\n",
    "    model, vectorizer = fit_model(train_data, TfidfVectorizer(), model)\n",
    "    score_and_evaluate_model(model, vectorizer, train_data, \"Train Data\")\n",
    "    print(\"=\" * 60)\n",
    "    score_and_evaluate_model(model, vectorizer, validation_data, \"Validation Data\")\n",
    "    print(\"=\" * 60)\n",
    "    model = fine_tune_model(model, vectorizer, train_data, validation_data)\n",
    "    return score_and_evaluate_model(model, vectorizer, test_data, \"Test Data\")\n",
    "\n",
    "\n",
    "models = sorted(MODELS.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2869e4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Evaluating Logistic Regression:\n",
      "\n",
      "Train Data Accuracy: 99.66 %\n",
      "Train Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3328\n",
      "           1       1.00      0.99      0.99      1075\n",
      "\n",
      "    accuracy                           1.00      4403\n",
      "   macro avg       1.00      0.99      1.00      4403\n",
      "weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "Train Data Confusion Matrix:\n",
      "[[3326    2]\n",
      " [  13 1062]]\n",
      "============================================================\n",
      "Validation Data Accuracy: 98.36 %\n",
      "Validation Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       412\n",
      "           1       1.00      0.93      0.97       138\n",
      "\n",
      "    accuracy                           0.98       550\n",
      "   macro avg       0.99      0.97      0.98       550\n",
      "weighted avg       0.98      0.98      0.98       550\n",
      "\n",
      "Validation Data Confusion Matrix:\n",
      "[[412   0]\n",
      " [  9 129]]\n",
      "============================================================\n",
      "Test Data Accuracy: 98.91 %\n",
      "Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       397\n",
      "           1       0.97      0.99      0.98       154\n",
      "\n",
      "    accuracy                           0.99       551\n",
      "   macro avg       0.98      0.99      0.99       551\n",
      "weighted avg       0.99      0.99      0.99       551\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      "[[393   4]\n",
      " [  2 152]]\n",
      "\n",
      "Training and Evaluating Random Forest:\n",
      "\n",
      "Train Data Accuracy: 100.0 %\n",
      "Train Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3328\n",
      "           1       1.00      1.00      1.00      1075\n",
      "\n",
      "    accuracy                           1.00      4403\n",
      "   macro avg       1.00      1.00      1.00      4403\n",
      "weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "Train Data Confusion Matrix:\n",
      "[[3328    0]\n",
      " [   0 1075]]\n",
      "============================================================\n",
      "Validation Data Accuracy: 98.36 %\n",
      "Validation Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       412\n",
      "           1       1.00      0.93      0.97       138\n",
      "\n",
      "    accuracy                           0.98       550\n",
      "   macro avg       0.99      0.97      0.98       550\n",
      "weighted avg       0.98      0.98      0.98       550\n",
      "\n",
      "Validation Data Confusion Matrix:\n",
      "[[412   0]\n",
      " [  9 129]]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "480 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "370 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\raini\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.90355406 0.91262116 0.90602319 0.91591674\n",
      " 0.89203143 0.90685984 0.90191477 0.91180832        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.30912832 0.30831208 0.314087   0.31160766 0.29841853 0.30006462\n",
      " 0.30254056 0.29842193        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.6281842  0.62738836\n",
      " 0.62406557 0.62242628 0.59356528 0.58696392 0.59438153 0.58944666\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.93324491 0.93325171 0.9348944  0.9349012\n",
      " 0.92251471 0.92830664 0.92333775 0.92666054        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.29015747 0.30170051 0.28603544 0.29922117 0.27366255 0.29181376\n",
      " 0.27612829 0.28934122        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.63392511 0.63314628\n",
      " 0.63475496 0.63233344 0.61411761 0.60344863 0.61412441 0.60263238\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.93406795 0.93737034 0.93817978 0.93570724\n",
      " 0.92500765 0.92829983 0.93077237 0.92994592        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.33385369 0.32562664 0.3322144  0.32067816 0.31901507 0.31655613\n",
      " 0.32149441 0.31326395        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.649648   0.65045744\n",
      " 0.65460327 0.65375642 0.62574227 0.62902765 0.62904806 0.62903105\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.94148896 0.94808353 0.94231881 0.94479135\n",
      " 0.93819338 0.93902323 0.93737034 0.94067612        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.31160426 0.3050301  0.31161106 0.29926198 0.30088766 0.29100432\n",
      " 0.29923817 0.29183417        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.64470292 0.64551916\n",
      " 0.64550556 0.64468932 0.61255654 0.61336598 0.6117335  0.6100704 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Accuracy: 98.19 %\n",
      "Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       397\n",
      "           1       0.99      0.94      0.97       154\n",
      "\n",
      "    accuracy                           0.98       551\n",
      "   macro avg       0.99      0.97      0.98       551\n",
      "weighted avg       0.98      0.98      0.98       551\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      "[[396   1]\n",
      " [  9 145]]\n",
      "\n",
      "Training and Evaluating Support Vector Machine:\n",
      "\n",
      "Train Data Accuracy: 100.0 %\n",
      "Train Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3328\n",
      "           1       1.00      1.00      1.00      1075\n",
      "\n",
      "    accuracy                           1.00      4403\n",
      "   macro avg       1.00      1.00      1.00      4403\n",
      "weighted avg       1.00      1.00      1.00      4403\n",
      "\n",
      "Train Data Confusion Matrix:\n",
      "[[3328    0]\n",
      " [   0 1075]]\n",
      "============================================================\n",
      "Validation Data Accuracy: 99.09 %\n",
      "Validation Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       412\n",
      "           1       1.00      0.96      0.98       138\n",
      "\n",
      "    accuracy                           0.99       550\n",
      "   macro avg       0.99      0.98      0.99       550\n",
      "weighted avg       0.99      0.99      0.99       550\n",
      "\n",
      "Validation Data Confusion Matrix:\n",
      "[[412   0]\n",
      " [  5 133]]\n",
      "============================================================\n",
      "Test Data Accuracy: 99.27 %\n",
      "Test Data Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       397\n",
      "           1       1.00      0.97      0.99       154\n",
      "\n",
      "    accuracy                           0.99       551\n",
      "   macro avg       1.00      0.99      0.99       551\n",
      "weighted avg       0.99      0.99      0.99       551\n",
      "\n",
      "Test Data Confusion Matrix:\n",
      "[[397   0]\n",
      " [  4 150]]\n",
      "\n",
      "Best Model: Support Vector Machine with Test Accuracy: 99.27 %\n"
     ]
    }
   ],
   "source": [
    "# Initialize the best model and accuracy\n",
    "best_model, best_accuracy = None, 0\n",
    "\n",
    "# Iterate over all models\n",
    "for model_name, model in models:\n",
    "    # Train and benchmark the model\n",
    "    test_accuracy = train_and_benchmark_model(model, model_name, TRAIN_DATASET, VALIDATION_DATASET, TEST_DATASET)\n",
    "\n",
    "    # Update the best model and accuracy if the current model is better\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_model, best_accuracy = model_name, test_accuracy\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(f\"\\nBest Model: {best_model} with Test Accuracy: {round(100 * best_accuracy, 2)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a689d0",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "\n",
    "### In the pursuit of creating an effective spam classification model, I have strategically chosen to prioritize the metric of recall. This decision is rooted in my primary objective of maximizing the identification of spam emails. Recall, often referred to as sensitivity or the true positive rate, quantifies the proportion of actual positives that are correctly classified. In the context of spam detection, a high recall signifies that my model is proficient at correctly flagging a substantial majority of spam emails, thereby shielding users from undesired content.\n",
    "\n",
    "### I consider this approach particularly vital in scenarios where the repercussions of overlooking a spam email (a false negative) outweigh those of erroneously marking a legitimate email as spam (a false positive). By optimizing for recall, I am fine-tuning my model to minimize the instances of spam emails that evade detection, thereby ensuring a more secure and clutter-free inbox experience for users.\n",
    "\n",
    "### However, I am cognizant of the need to maintain a balance with precision to prevent an excessive number of legitimate emails from being inaccurately flagged as spam. This careful calibration between recall and precision is what I believe will drive the success of my spam classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3b97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b88104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
